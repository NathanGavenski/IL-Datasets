{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f514d0-11e0-4028-a136-8694edd629aa",
   "metadata": {},
   "source": [
    "# Training Assistance\n",
    "\n",
    "## Loading a local file\n",
    "\n",
    "If you created a dataset using the ‚ÄòController‚Äô class. You can load the data by simply using the ‚ÄòBaselineDataset‚Äô class and inform the path to the local file.\n",
    "\n",
    "---\n",
    "\n",
    "Dataset will have information about the average reward from the ‚Äòteacher‚Äô and consists of tuples of (ùë†, ùëé, ùë†‚Ä≤ ), where ùë† is the current state, and ùë†‚Ä≤ the next state given action ùëé. Additionally, if the user wants to access the original information, the ‚ÄòBaselineDataset‚Äô provides it on ‚Äòdataset.data‚Äô, which is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "115133de-8037-45ff-891d-8739172aaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation_datasets.dataset import BaselineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8934468a-40ad-4788-94d4-9b0bfddfb863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1539.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = BaselineDataset(\"./dataset/pendulum/teacher.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de0b9090-455c-4f06-a417-da47ea4fc5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-100.08150779832427, torch.Size([19900, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.average_reward, dataset.states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4604d9b-dcc8-4e12-bfdb-4b59cb0cddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1]), torch.Size([3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, action, next_state = dataset[0]\n",
    "state.shape, action.shape, next_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7336b-6c3f-4868-b284-52413be0f745",
   "metadata": {},
   "source": [
    "## Using to assist training\n",
    "\n",
    "Simple example for training a Behavioural Cloning agent in LunarLander-v2 environment.\n",
    "In this example, we are using a simplistic training/evaluation loop to train an MLP with 2 hidden layers, each with 32 neurons and a output layer with 4 neurons, the Adam optimizer and a Cross Entropy loss function.\n",
    "We divide the data into a 70/30 split, with 700 episodes to train the agent and 300 to evaluate.\n",
    "\n",
    "The data is available at: https://huggingface.co/datasets/NathanGavenski/LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97afb014-5195-47a4-a91e-af04e4c92ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import MLP\n",
    "\n",
    "from imitation_datasets.dataset import BaselineDataset\n",
    "from imitation_datasets.dataset.metrics import accuracy as accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078dd077-40c8-4114-bcc1-dd106258158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: optim.Optimizer = None,\n",
    "    loss_fn: nn.Module = None,\n",
    "    train: bool = False\n",
    ") -> Union[Tuple[float, float], float]:\n",
    "    \"\"\"This is a loop to train and evaluate the model.\"\"\"\n",
    "    model = model.train() if train else model.eval()\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    for (state, action, next_state) in dataloader:\n",
    "        bc.zero_grad()\n",
    "        predictions = model(state.float())\n",
    "        if train:\n",
    "            loss = loss_fn(predictions, action.squeeze(-1).long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc = accuracy_fn(predictions, action.squeeze(-1))\n",
    "        if train:\n",
    "            epoch_loss.append(loss.item())\n",
    "        epoch_acc.append(acc)\n",
    "    if train:\n",
    "        return np.mean(epoch_loss), np.mean(epoch_acc)\n",
    "    return np.mean(epoch_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a6ebce-eec2-4a05-a197-3253446efb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 700/700 [00:01<00:00, 593.86it/s]\n",
      "Creating dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 1389.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Avg Loss: 0.3667 Avg Acc: 86.43%\n",
      "Eval - Avg Acc: 94.02%\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "bc = MLP(in_channels=8, hidden_channels=[32, 32, 4], activation_layer=LeakyReLU)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bc.parameters(), lr=1e-3)\n",
    "\n",
    "# Data\n",
    "dataset_train = BaselineDataset(\"NathanGavenski/LunarLander-v2\", source=\"hf\", n_episodes=700)\n",
    "dataset_eval = BaselineDataset(\"NathanGavenski/LunarLander-v2\", source=\"hf\", n_episodes=700, split=\"eval\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_eval = DataLoader(dataset_eval, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train\n",
    "loss, acc = loop(bc, dataloader_train, optimizer, loss_fn, train=True)\n",
    "print(f\"Train - Avg Loss: {round(loss, 4)} Avg Acc: {round(acc, 2)}%\")\n",
    "\n",
    "# Eval\n",
    "acc = loop(bc, dataloader_eval, train=False)\n",
    "print(f\"Eval - Avg Acc: {round(acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac72dbbb-359e-484a-9bcc-8337adf0c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Reward: 221.979\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "state, _ = env.reset()\n",
    "acc_reward = 0\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        action = torch.argmax(bc(torch.from_numpy(state)[None]), dim=1).item()\n",
    "        state, reward, done, terminated, info = env.step(action)\n",
    "        done |= terminated\n",
    "        acc_reward += reward\n",
    "print(f\"Test Reward: {round(acc_reward, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2b26d-c5e6-4693-849a-b58f6f448cf2",
   "metadata": {},
   "source": [
    "## Using as inheritance\n",
    "\n",
    "An example for using ‚ÄòBaselinesDataset‚Äô in inheritance to create a sequential dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66902b97-8c31-4032-b0fb-affbb463ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22e876a9-28ae-4730-91a1-1eefcf62d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(BaselineDataset):\n",
    "    \"\"\"\n",
    "    Squence dataset for the BaselineDataset from IL-Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        source: str = \"local\",\n",
    "        split: str = \"train\",\n",
    "        n_episodes: int = None,\n",
    "    ) -> None:\n",
    "        super().__init__(path, source, split, n_episodes)\n",
    "        episode_starts = list(np.where(self.data[\"episode_starts\"] == 1)[0])\n",
    "        episode_starts.append(len(self.data[\"episode_starts\"]))\n",
    "        \n",
    "        if n_episodes is not None:\n",
    "            if split == \"train\":\n",
    "                episode_starts = episode_starts[:n_episodes + 1]\n",
    "            else:\n",
    "                episode_starts = episode_starts[n_episodes:]\n",
    "\n",
    "        self.lenghts = []\n",
    "        self.sequences = []\n",
    "        self.sequences_actions = []\n",
    "        for start, end in zip(episode_starts, tqdm(episode_starts[1:], desc=\"Creating sequence\")):\n",
    "            episode = self.data[\"obs\"][start:end]\n",
    "            episode = torch.from_numpy(episode)\n",
    "            actions = torch.from_numpy(self.data[\"actions\"][start:end].reshape((-1, 1)))\n",
    "            self.lenghts.append(episode.shape[0])\n",
    "            self.sequences.append(episode)\n",
    "            self.sequences_actions.append(actions)\n",
    "\n",
    "        self.sequences = pad_sequence(self.sequences, batch_first=True)\n",
    "        self.sequences_actions = pad_sequence(self.sequences_actions, batch_first=True)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.sequences.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, list[int]]:\n",
    "        return self.sequences[index], self.lenghts[index], self.sequences_actions[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21bfbcd-9895-445f-986f-b13372f9e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1538.19it/s]\n",
      "Creating sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1689.63it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = SequenceDataset(\"./dataset/pendulum/teacher.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e79ae4-4f83-421a-a575-c4d3b09bb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 200, 3]), torch.Size([100, 200, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sequences.shape, dataset.sequences_actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78d15a5e-25cf-4a98-9ad9-b8ed7bb915c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 3]), 200, torch.Size([200, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode, length, action = dataset[0]\n",
    "episode.shape, length, action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f7e39-f773-4741-a174-816d5af5191e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
